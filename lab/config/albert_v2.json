{
    "model": {
        "vocab_size": 10000,
        "embedding_size": 256,
        "hidden_size": 512,
        "num_hidden_layers": 3,
        "num_attention_heads": 8,
        "intermediate_size": 512,
        "max_position_embeddings": 512
    },
    "train": {
        "num_train_epochs": 10,
        "per_device_train_batch_size": 32,
        "save_steps": 10000,
        "fp16": true,
        "gradient_accumulation_steps": 16
    },
    "path": {
        "result": "results/v2",
        "data": "data/dataset/v1",
        "tokenizer": "resources/tokenizer"
    }
}